{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOGQ8pnmx8Lv5PeowJCckh5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlirezaParchami/Real-time-Character-Detection-using-Faster-RCNN/blob/main/train_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sxdzoKO30XZ"
      },
      "source": [
        "Install Dependencies and Detectron2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIvpKFRj3WLz"
      },
      "source": [
        "!pip install pyyaml==5.1\r\n",
        "import torch, torchvision\r\n",
        "print(torch.__version__, torch.cuda.is_available())\r\n",
        "!gcc --version\r\n",
        "\r\n",
        "import torch\r\n",
        "assert torch.__version__.startswith(\"1.7\")\r\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.7/index.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRBQXX9v3xRA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85c6fb5c-b07d-4186-a715-8be13c0378c7"
      },
      "source": [
        "import detectron2\r\n",
        "from detectron2.utils.logger import setup_logger\r\n",
        "setup_logger()\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import os, json, cv2, random\r\n",
        "from google.colab.patches import cv2_imshow\r\n",
        "\r\n",
        "from detectron2.engine import DefaultPredictor\r\n",
        "from detectron2.config import get_cfg"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPi788WY5aSL"
      },
      "source": [
        "#Download Character Dataset and unzip\r\n",
        "#!wget https://github.com/MinhasKamal/AlphabetRecognizer/files/1084725/English.Alphabet.Dataset.zip\r\n",
        "!unzip English.Alphabet.Dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDsifkh6bPnM",
        "outputId": "5b7f3502-2e51-4204-9718-7e964b6198e0"
      },
      "source": [
        "#Version 1\r\n",
        "from detectron2.structures import BoxMode\r\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\r\n",
        "\r\n",
        "def get_character_dict(img_dir, num):\r\n",
        "  dir = img_dir + str(num)+ \"/\" + str(num) + \".json\"\r\n",
        "  json_file = os.path.join(dir)\r\n",
        "  \r\n",
        "  with open(json_file) as f:\r\n",
        "    imgs_anns = json.load(f)\r\n",
        "  \r\n",
        "  character_dicts = []\r\n",
        "  for idx, v in zip(imgs_anns.keys(), imgs_anns.values()):\r\n",
        "    record = {}\r\n",
        "\r\n",
        "    filename = os.path.join(img_dir + str(num) + \"/\" + v[\"filename\"])\r\n",
        "    height, width = cv2.imread(filename).shape[:2]\r\n",
        "\r\n",
        "    record[\"file_name\"] = filename\r\n",
        "    record[\"image_id\"] = idx\r\n",
        "    record[\"height\"] = height\r\n",
        "    record[\"width\"] = width\r\n",
        "\r\n",
        "    annos = v[\"regions\"]\r\n",
        "    objs = []\r\n",
        "    for _, anno in annos.items():\r\n",
        "      anno = anno[\"shape_attributes\"]\r\n",
        "      px = anno[\"points_x\"]\r\n",
        "      py = anno[\"points_y\"]\r\n",
        "      poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]\r\n",
        "      poly = [p for x in poly for p in x]\r\n",
        "\r\n",
        "      obj = {\r\n",
        "          \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\r\n",
        "          \"bbox_mode\": BoxMode.XYXY_ABS,\r\n",
        "          \"segmentation\": [poly],\r\n",
        "          \"category_id\": num - 1,\r\n",
        "      }\r\n",
        "      objs.append(obj)\r\n",
        "    record[\"annotations\"] = objs\r\n",
        "    character_dicts.append(record)\r\n",
        "  return character_dicts\r\n",
        "  \r\n",
        "\r\n",
        "for d in range(1,8):\r\n",
        "  DatasetCatalog.register(\"character_train_\" + str(d), lambda d=d: get_character_dict(\"English Alphabet Dataset/\", d))\r\n",
        "  MetadataCatalog.get(\"character_train_\" + str(d)).set(thing_classes=[str(d)])\r\n",
        "character_metadata = MetadataCatalog.get(\"character_train\")\r\n",
        "print(\"Finished Successfully\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished Successfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wKxIw7sbwQ_",
        "outputId": "4ebcb53c-e9ab-4a4a-d8dc-268d085ea260"
      },
      "source": [
        "#Version 2\r\n",
        "from detectron2.structures import BoxMode\r\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\r\n",
        "\r\n",
        "def get_character_dict(img_dir):\r\n",
        "  dataset_dicts = []\r\n",
        "  for num in range(1,8):\r\n",
        "    dir = img_dir + str(num)+ \"/\" + str(num) + \".json\"\r\n",
        "    json_file = os.path.join(dir)\r\n",
        "  \r\n",
        "    with open(json_file) as f:\r\n",
        "      imgs_anns = json.load(f)\r\n",
        "  \r\n",
        "    character_dicts = []\r\n",
        "    for idx, v in zip(imgs_anns.keys(), imgs_anns.values()):\r\n",
        "      record = {}\r\n",
        "\r\n",
        "      filename = os.path.join(img_dir + str(num) + \"/\" + v[\"filename\"])\r\n",
        "      height, width = cv2.imread(filename).shape[:2]\r\n",
        "\r\n",
        "      record[\"file_name\"] = filename\r\n",
        "      record[\"image_id\"] = idx\r\n",
        "      record[\"height\"] = height\r\n",
        "      record[\"width\"] = width\r\n",
        "\r\n",
        "      annos = v[\"regions\"]\r\n",
        "      objs = []\r\n",
        "      for _, anno in annos.items():\r\n",
        "        anno = anno[\"shape_attributes\"]\r\n",
        "        px = anno[\"points_x\"]\r\n",
        "        py = anno[\"points_y\"]\r\n",
        "        poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]\r\n",
        "        poly = [p for x in poly for p in x]\r\n",
        "\r\n",
        "        obj = {\r\n",
        "            \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\r\n",
        "            \"bbox_mode\": BoxMode.XYXY_ABS,\r\n",
        "            \"segmentation\": [poly],\r\n",
        "            \"category_id\": num - 1,\r\n",
        "        }\r\n",
        "        objs.append(obj)\r\n",
        "      record[\"annotations\"] = objs\r\n",
        "      character_dicts.append(record)\r\n",
        "\r\n",
        "    dataset_dicts.extend(character_dicts)\r\n",
        "  return dataset_dicts\r\n",
        "  \r\n",
        "\r\n",
        "for d in [\"train\"]:\r\n",
        "  DatasetCatalog.register(\"character_\" + d, lambda d=d: get_character_dict(\"English Alphabet Dataset/\" + d + \"/\"))\r\n",
        "  MetadataCatalog.get(\"character_\" + str(d)).set(thing_classes=[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\"])\r\n",
        "character_metadata = MetadataCatalog.get(\"character_train\")\r\n",
        "print(\"Finished Successfully\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished Successfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKoLgcuBRkjK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "a95d4040-7413-4eff-8993-c618c17ecfe9"
      },
      "source": [
        "#Check if the metadata is added successfully\r\n",
        "\r\n",
        "from detectron2.utils.visualizer import Visualizer\r\n",
        "dataset_dicts = get_character_dict(\"English Alphabet Dataset/train/\")\r\n",
        "\r\n",
        "for d in random.sample(dataset_dicts, 3):\r\n",
        "  print(d)\r\n",
        "  img = cv2.imread(d[\"file_name\"])\r\n",
        "  visualizer = Visualizer(img[:, :, ::-1], metadata=character_metadata, scale=0.5)\r\n",
        "  out = visualizer.draw_dataset_dict(d)\r\n",
        "  cv2_imshow(out.get_image()[:, :, ::-1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "here\n",
            "30\n",
            "60\n",
            "90\n",
            "120\n",
            "150\n",
            "180\n",
            "210\n",
            "210\n",
            "5\n",
            "{'file_name': 'English Alphabet Dataset/train/1/1_2.png', 'image_id': '1_2', 'height': 60, 'width': 60, 'annotations': [{'bbox': [2, 6, 58, 56], 'bbox_mode': <BoxMode.XYXY_ABS: 0>, 'segmentation': [[2.5, 6.5, 58.5, 56.5]], 'category_id': 0}]}\n",
            "{'file_name': 'English Alphabet Dataset/train/3/3_29.png', 'image_id': '3_29', 'height': 60, 'width': 60, 'annotations': [{'bbox': [2, 6, 58, 56], 'bbox_mode': <BoxMode.XYXY_ABS: 0>, 'segmentation': [[2.5, 6.5, 58.5, 56.5]], 'category_id': 2}]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAIAAAC0Ujn1AAADa0lEQVR4nNWVv0vzWhjHT05O00h/2Giw1TZq/VGxg4K1ujgWdVFwcBAnwcFB/FcEcVKcCjq5xFkQxZBiB/EH0hbFtkpRhGJqm5A0yR3S2zek79tb7tXhPktOvnnO53xP8pwnmK7r4GcC/hAXAIBFIpHfPkgmk+ZbXdc1TVNVtb5LCKHNZmuCRsaFIIj9/X2bzYbj+Onp6d7eHgCgWq2KomgkKIpSLBYLhUK5XDaU9vb2cDiMYRgAAMfxtrY2Y2xFy7K8sbEhiiKO4wcHBxzHCYKQz+dvb2//ZKpYLD4/Pxtjh8MxPj5O07R5AVRPNQwihHAclyTp6OgonU432a8lzs7OpqenI5HI4OCgFQ0hjMfjDMPE4/Hz83O/398614hEIvH6+jo1NTU5OWm323+hNU1bWlqiKGp7ezsUCpnn9Pf3Dw8POxwOy9sEAHAc9/b2Vr99eXn5/PwMBAI+nw+Z8yRJenx8TCQSCwsLpVKpVCphGBaLxcLhsNfrJQiiEe33+3meN5dTpVK5v7+32+21una73bIsS5JEkmQ0Gk2lUpubmzRNYxg2NDTEMIzdbm/kAgCCwWB3d7dZUVVVEARZlmuuaZre2dmBEEIIWZZlWTYWi21tbamq2lhVrYQgCLUjo6rq+/u7qqr1Z6urq7Ozs3Nzc/9I0TRN0zSzgmEYhLDm+redJJfLtWLQ2GujjgAAsix/fX2ZLX9LoGQymcvlOI67urr6XvQPdr4fRjMMMz8/7/F4vheNwN+18q8RkiRVKhWzQhAEQRDoTxMAAKIoZrNZr9dLkmSTNJ7nT05OzEo0Gh0bG6uZRQgFg0G3223OyGazu7u7+Xy+yf+zWq0qitKoO53OGpokycXFxYGBAUuGrus3NzeZTEYURcsC9V+a0+k06wihzs5OkiQx84SHh4dkMnl9fW1ZoKenp6+vz9JMdF3Xdf3p6Wl5eTmTybAsa6BcLtf6+npXVxdm8ZLNZi8uLlKplOXLNAmSJNfW1srl8uHhYW9v78zMTDgcttlsVrRx6D8+Pi4vL+/u7lqkI4RWVlYCgYCiKPUea60QgiA6OjooivL5fCMjI8fHx62gKYpyuVwejwfH8bpodW0OVVUlSTLG5XI5nU7zPF8oFAAAo6OjExMToVDIePsQQpIkLW29Gfo/xv+zPf0FiBF5rUujiGEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=30x30 at 0x7F13915EAE80>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'file_name': 'English Alphabet Dataset/train/2/2_30.png', 'image_id': '2_30', 'height': 60, 'width': 60, 'annotations': [{'bbox': [1, 3, 58, 57], 'bbox_mode': <BoxMode.XYXY_ABS: 0>, 'segmentation': [[1.5, 3.5, 58.5, 57.5]], 'category_id': 1}]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAIAAAC0Ujn1AAAEEklEQVR4nLWWb0wbZRzHf3d9Wlrr0XaUtZTBEGg3WrGI08XRVUaJrsk4RucWJiADSQANODRG3ywmvCOZwbkli8qLomkidYO12QgR4gtggUQ2JMtggbGuwRZhLR2Qrtd/d76gqZU/NQP2fXN3z/O9z/3ye5775sFuX59YXnwGL0BYpkwR8IXYCax1E63nLu8UnSHJZjz8k698xUciBpg/3D0j7l8AQJ2sKSws1Bw9ug3oyoI3SIUQSkBIiPr/+t4ndCA2OiO+NO0bXvQ/eip8LDmcoKlQbQM9bLrvti/jAODHV3yJjtVFX4AKPPE/SkR7t4HbKHztwmKzpNkitCKQcXPmfPd2BY2idzwun1Rc6LNfCQfomOEdo3FgFWKfPQwNTjy7yQkTGIMBs1N0pCFFRNMyOO6FrAzG+DmrOI1k84cYekd4HABkHOVB7jEpqE5x25szuw4QBX7OKjvAn/7ZGwqGt43GstMPhgNhFodFJPEoirLZbGsTWRnyArw8fX9aY+cJNvc/vadpuqury2w2z8/PkyRZU1OTkpISa1jbfFuuF4OHcz7iB2+jS2du1HYU9/520263j4yMuFyuWJvVarVarQDA4/EqKysNBoNIJIpU3Xt1xG1fTtov0FSoZmZmqqqqoq/V19dXf1jdXtk1MfTg9eak0x8YBALBugpMJpPRaIw+8vn81tZW5rEwXtUA0NfXNzk5mf52+jviw3NWt6B2D0G8tM7T0NCg1WqNRuPg4CAAeL3ejo4Ozb4TYl4KHgdNEIROp2v8uLH2O736vcy24+Ylx+pGm1KpbGlpKS0tRQgBwNTUlMfjgejm21QKhUKtViOEMAwru1BQUKlq05uf2J5udAqFQp1Ot4Zeo8/OzsZDJycnxy69/vybx5sPtenNzgfudU4ejyeXy3E8QnM4HH8vLMRDb9SxOrXha83Fkmv2Pxf+1/x8aAA4clZZ8U1Ru6F7ZtSxy2gAeIOU1/2gv3LWev93+y6jAeDV4oxPTCU/1vWO33q4y2gAUBzZd/5a2U+fDoyapzY17CiYM/Kln1vf/9bQ7fcGXzuZFh3Py8s7kJYTD+33+ymK4nK5cTz7lOIvbp2+SP56Z3Q8HI7EpFgs3iMSxWuIxWKJzYetJMkSnbqcf/e6LXEuGxhoamrKzc2F+A3xeDwDAwM4jpMkKZFIMAzb6HE6nRaLpbOzMyGLn+UsKla9W1ZWcrfHRrm3jqfq6urU1NShoSGTydTf3y+VSje1OZ1OmqbLy8u1Wq1MnNZxrt/85XDmWzKIhiqbixIl/CX3Uk9PNwCQJJm8998jA0PTFEW5XK6xsTtLS5G/PD8/Xy6Xv0wQsV8KUqGBq+OIg+fpMyPoOG15XoWD9NiN6VSVGHsRx0k6TGM49g+NIpONcubayAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=30x30 at 0x7F13914C0320>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'file_name': 'English Alphabet Dataset/train/5/5_18.png', 'image_id': '5_18', 'height': 60, 'width': 60, 'annotations': [{'bbox': [1, 6, 58, 56], 'bbox_mode': <BoxMode.XYXY_ABS: 0>, 'segmentation': [[1.5, 6.5, 58.5, 56.5]], 'category_id': 4}]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAIAAAC0Ujn1AAAFDklEQVR4nLWVa0xTdxjGn3PhUloyCqUBBNqKGsTaDBGn7eSibiyZ2XALLBnzFru425clLtPtA3FxfMBEFjNF3YdKTHS0K1NSBjEBMW7RRKJsw0rH1dlCgVJaoKW09Pz3oUjw9BKTxefbed/3+Z33/C/voQgheDmiXxIXAKVaV8QFQFH8RGttz1JwyTPvcbvd0czJyclCoZBlWZqO0CIbcCPghv5i68KiN8gFg8Hg53UHCCH9d55OOxxDQ0N9j/qiodev37BWoUiXSjMyMoRCIR/NJCHoAeFwrOHo/KKbEBBmyePxXum4YBuzxf7kyYHRPwYgSZMUFhYqlUqlUskwDACfHUEfWIoC+wooCv4pUFLOT7yTk5Ozs7NXZ+p4oCNHjshkMgDDw8MGg8Hj8SwnpmG6k5A3lndUcbSmpiYtLW30MjyjwGZ5UUFm0YPL1tvnzbd+MGvf/pJHlEqlWq22ra1tfHzc6/V6vV6bzdbc3Jyfn7+6jKbp9PT0pqamqampER3pqyXL6FJVRV5eXk5q3u2z/eWb9q72aDQap9NJnlcgEOjs7CwvL+f1IZFIjEbjwE+BvlqyvLPjU2Mul+upc8h01/DahlIxMkPxqqoqg8EgFov5W8Sy5eXlcrmcF3c4HCaTyWq1InSuE+MTadDT09OChKSdhbvuP7mVhFc+g04QJ5RIJJmZmRH3kKKoEydOaLVaXlyn05nNZo7jWABCQfKZry4FuADLsL/evtr54DcKtAipp0TditftEbkh5ebmZmVlhcetNqs9xc4CGP53cO8XJfOYXskRcKex78yarvhTb3pLkJQdGc0wTOi08fTY/FiWuDHqRSfgZvZ1yffTXWq4/opcYzabBwcHw+MzrpnZ2Vk2GhrA9RvXBzYNrMnZ4dp24L76x6mMR7wCq9VqsVii+kd0pH6rqRQHY7xjI3Zegr0E+2PUrFYpDtZvNb3Q5HuMOydRVo2T7+HbF6QDiLUgZWVlGo1m5XFqrvkd/advZFRa32oFw8Uwiv8sVIjWxUKr1erjx4+LRKKVyNL3uPvBmk29W7frEZcc1RiaIbEWxG63h+7VilgRNDcgyEF3CRbGYliB0G3crFJtK94Wnuvv7+/t7eUbWBRdRHYVutRwrzoyPp9Pp9MVFxfLZDKj8ZeZmRmM6MjDb/xn32+lwv80wOHDh0kUjV4hN6Rk4hYhhLhcLr1eLxAIQq4yHDpd3EYDiIuLU8gVu3fvjrgm4Y2HJPsI26/hXjX5u9FtMBiqq6sXFhZCqR3qHa8WFiI0W/+55DeZTEqlMhyhUqm6urp8Ph/HcbzG/X7/faPlSvL0u/h6pb6goODnT+711ZJl9IiOzM3NdXZ27tq1Kz4+nkdPSUmpq6vr6OiwWq3z8/OEEKfTqdfr6+vr9+zZI0ZWPR5qcZ4GU1FRcfPmzf4Lvr5aQo3oiGcUQjnkh7C4uGixWM6dO9fS0uJwOHgvyM/PV6lUYrFYKBQ6nc729vaJiYlQSoDkY3RLVm6GRs9sUK0dv5bgGcVzaAAcx9nt9u7u7oaGhp6enoirzFNqaqparf6wuiano3LBkrCzjbK3IwI6JL/fb7PZhoeHjUZjY2NjNGhFRUVlZeWWLVuys7OlUinDsObv8KQJio/BLT5DM4lIzOA7CSHBYDCwFIiGZhmWpmmaplcfXMfveNqM7OpnMyTog2c03EsBbIw5448UFGQjax9YEdjwZv+/hHIA+A+4TWXEWJJVlgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=30x30 at 0x7F139147B940>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rT9FRG6xN6eK"
      },
      "source": [
        "**Train the Model**\r\n",
        "\r\n",
        "Want to fine-tune a COCO-pretrained R50-FPN 3x with model reference number of 137849458 for Faster RCNN\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LNLzfkUN830"
      },
      "source": [
        "from detectron2.engine import DefaultTrainer\r\n",
        "from detectron2 import model_zoo\r\n",
        "\r\n",
        "cfg = get_cfg()\r\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\r\n",
        "#cfg.DATASETS.TRAIN = (\"character_train_1\",\"character_train_2\", \"character_train_3\", \"character_train_4\", \"character_train_5\",\"character_train_6\",\"character_train_7\",)\r\n",
        "cfg.DATASETS.TRAIN = (\"character_train\",)\r\n",
        "cfg.DATASETS.TEST = ()\r\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\r\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\r\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\r\n",
        "cfg.SOLVER.BASE_LR = 0.0002\r\n",
        "cfg.SOLVER.MAX_ITER = 40\r\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\r\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 7\r\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93SXm0dESNMx",
        "outputId": "0e48e7f8-3a85-4e57-a41c-c30cd158efe0"
      },
      "source": [
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\r\n",
        "trainer = DefaultTrainer(cfg) \r\n",
        "trainer.resume_or_load(resume=False)\r\n",
        "trainer.train()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[01/19 07:25:00 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=8, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=28, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "here\n",
            "30\n",
            "60\n",
            "90\n",
            "120\n",
            "150\n",
            "180\n",
            "210\n",
            "\u001b[32m[01/19 07:25:00 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 210 images left.\n",
            "\u001b[32m[01/19 07:25:00 d2.data.build]: \u001b[0mDistribution of instances among all 7 categories:\n",
            "\u001b[36m|  category  | #instances   | category   | #instances   | category   | #instances   |\n",
            "|:----------:|:-------------|:-----------|:-------------|:-----------|:-------------|\n",
            "|     1      | 30           | 2          | 30           | 3          | 30           |\n",
            "|     4      | 30           | 5          | 30           | 6          | 30           |\n",
            "|     7      | 30           |            |              |            |              |\n",
            "|   total    | 210          |            |              |            |              |\u001b[0m\n",
            "\u001b[32m[01/19 07:25:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[01/19 07:25:00 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[01/19 07:25:00 d2.data.common]: \u001b[0mSerializing 210 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[01/19 07:25:00 d2.data.common]: \u001b[0mSerialized dataset takes 0.09 MiB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "model_final_280758.pkl: 167MB [00:06, 24.5MB/s]                           \n",
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (8, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (28, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (28,) in the model! You might want to double check if this is expected.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[01/19 07:25:12 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/detectron2/modeling/roi_heads/fast_rcnn.py:217: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero()\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  num_fg = fg_inds.nonzero().numel()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[01/19 07:25:19 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 19  total_loss: 2.111  loss_cls: 1.994  loss_box_reg: 0.09491  loss_rpn_cls: 0.004397  loss_rpn_loc: 0.006706  time: 0.3354  data_time: 0.0128  lr: 3.9962e-06  max_mem: 1991M\n",
            "\u001b[32m[01/19 07:25:27 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 39  total_loss: 1.871  loss_cls: 1.757  loss_box_reg: 0.09663  loss_rpn_cls: 0.003651  loss_rpn_loc: 0.006932  time: 0.3392  data_time: 0.0055  lr: 7.9922e-06  max_mem: 1991M\n",
            "\u001b[32m[01/19 07:25:28 d2.engine.hooks]: \u001b[0mOverall training speed: 38 iterations in 0:00:12 (0.3393 s / it)\n",
            "\u001b[32m[01/19 07:25:28 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:14 (0:00:01 on hooks)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_JnwjxcSj7y"
      },
      "source": [
        "**Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXnDioJTSlpO"
      },
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\r\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\r\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}